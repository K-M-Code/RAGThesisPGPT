server:
  env_name: ${APP_ENV:vllm}

llm:
  mode: openailike
  max_new_tokens: 512
  context_window: 3900
  tokenizer: meta-llama/Meta-Llama-3-8B-Instruct

embedding:
  mode: huggingface
  ingest_mode: batch
#  count_workers: 2
  embed_dim: 1024

rag:
  similarity_top_k: 10
  rerank:
    enabled: yes
    model: cross-encoder/ms-marco-MiniLM-L-2-v2
    top_n: 4

huggingface:
  embedding_hf_model_name: mixedbread-ai/mxbai-colbert-large-v1

vectorstore:
  database: postgres

nodestore:
  database: postgres

openai:
  prompt_style: "mistral"
  api_base: ${API_URL}
  api_key: EMPTY
  model: QuantFactory/Meta-Llama-3-8B-Instruct-GGUF


postgres:
  host: ${PG_DATABASE_IP_VARIABLE}
  port: ${PG_DATABASE_PORT_VARIABLE}
  database: ${PG_DATABASE_VARIABLE}
  user: ${PG_USER_VARIABLE}
  password: ${PG_PASSWORD_VARIABLE}
  schema_name: ${PG_SCHEMA_VARIABLE}